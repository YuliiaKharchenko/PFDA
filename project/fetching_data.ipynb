{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Data for the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Pandas](https://pandas.pydata.org/docs/)\n",
    "- [Requests: HTTP for Humans™](https://requests.readthedocs.io/en/latest/)\n",
    "- [io — Core tools for working with streams](https://docs.python.org/3/library/io.html)\n",
    "- [os — Miscellaneous operating system interfaces](https://docs.python.org/3/library/os.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Selection of Data for Analysis\n",
    "\n",
    "Based on my research and exploration of available data sources, I decided to take a broader approach and conduct an overall analysis of the current weather stations in Ireland and their corresponding data availability. This decision was made to gain a comprehensive understanding of the wind speed variability and its distribution over time. By focusing on these stations, I aim to explore how wind speeds fluctuate across the country, providing a solid foundation for further analysis of wind patterns and trends. This will help shape the direction of my future analyses, enabling more detailed assessments of wind energy potential in Ireland. \n",
    "The names and IDs used in the dictionary were collected manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of station names and IDs\n",
    "stations = {\n",
    "    \"Athenry\": 1875,\n",
    "    \"Ballyhaise\": 675,\n",
    "    \"Belmullet\": 2375,\n",
    "    \"Casement\": 3723,\n",
    "    \"Claremorris\": 2175,\n",
    "    \"Cork Airport\": 3904,\n",
    "    \"Dublin Airport\": 532,\n",
    "    \"Dunsany\": 1375,\n",
    "    \"Finner\": 2075,\n",
    "    \"Gurteen\": 1475,\n",
    "    \"Johnstown Castle\": 1775,\n",
    "    \"Knock Airport\": 4935,\n",
    "    \"Malin Head\": 1575,\n",
    "    \"Mace Head\": 275,\n",
    "    \"Moore Park\": 575,\n",
    "    \"Mount Dillon\": 1975,\n",
    "    \"Mullingar\": 875,\n",
    "    \"Newport\": 1175,\n",
    "    \"Oak Park\": 375,\n",
    "    \"Roches Point\": 1075,\n",
    "    \"Shannon Airport\": 518,\n",
    "    \"Sherkin Island\": 775,\n",
    "    \"Valentia Observatory\": 2275\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly1875.csv for station: Athenry (ID: 1875)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly675.csv for station: Ballyhaise (ID: 675)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly2375.csv for station: Belmullet (ID: 2375)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly3723.csv for station: Casement (ID: 3723)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly2175.csv for station: Claremorris (ID: 2175)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly3904.csv for station: Cork Airport (ID: 3904)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly532.csv for station: Dublin Airport (ID: 532)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly1375.csv for station: Dunsany (ID: 1375)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly2075.csv for station: Finner (ID: 2075)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly1475.csv for station: Gurteen (ID: 1475)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly1775.csv for station: Johnstown Castle (ID: 1775)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly4935.csv for station: Knock Airport (ID: 4935)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly1575.csv for station: Malin Head (ID: 1575)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly275.csv for station: Mace Head (ID: 275)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly575.csv for station: Moore Park (ID: 575)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly1975.csv for station: Mount Dillon (ID: 1975)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly875.csv for station: Mullingar (ID: 875)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly1175.csv for station: Newport (ID: 1175)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly375.csv for station: Oak Park (ID: 375)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly1075.csv for station: Roches Point (ID: 1075)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly518.csv for station: Shannon Airport (ID: 518)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly775.csv for station: Sherkin Island (ID: 775)...\n",
      "Fetching data from https://cli.fusio.net/cli/climate_data/webdata/dly2275.csv for station: Valentia Observatory (ID: 2275)...\n"
     ]
    }
   ],
   "source": [
    "# Base URL\n",
    "base_url = \"https://cli.fusio.net/cli/climate_data/webdata/dly{}.csv\"\n",
    "\n",
    "# Folder to store data\n",
    "data_folder = \"Data\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Loop to fetch and save data\n",
    "for station_name, station_id in stations.items():\n",
    "    url = base_url.format(station_id)\n",
    "    print(f\"Fetching data from {url} for station: {station_name} (ID: {station_id})...\")\n",
    "\n",
    "    try:\n",
    "        # Download the data, skipping the first 24 rows\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        station_data = pd.read_csv(StringIO(response.text), skiprows=24, skipinitialspace=True)\n",
    "        \n",
    "        # Save to CSV in the Data folder with station name and ID in the filename\n",
    "        file_path = os.path.join(data_folder, f\"{station_name}_station_{station_id}.csv\")\n",
    "        station_data.to_csv(file_path, index=False)\n",
    "    \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for station {station_name} (ID: {station_id}): {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns of interest\n",
    "columns_of_interest = ['date', 'maxtp', 'mintp', 'rain', 'cbl', 'wdsp', 'hm', 'ddhm', 'hg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data saved to All_stations_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Reverse the dictionary for quick lookup\n",
    "station_ids_to_names = {v: k for k, v in stations.items()}\n",
    "\n",
    "# Output file path\n",
    "output_file = \"All_stations_data.csv\"\n",
    "\n",
    "# Initialize an empty list for combined data\n",
    "combined_data = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for file_name in os.listdir(data_folder):\n",
    "    try:\n",
    "        # Extract station ID from the file name\n",
    "        station_id = int(file_name.split('_')[-1].split('.')[0])\n",
    "        station_name = station_ids_to_names.get(station_id, \"Unknown\")\n",
    "        \n",
    "        # Read the data and add columns\n",
    "        file_path = os.path.join(data_folder, file_name)\n",
    "        station_data = pd.read_csv(file_path)[columns_of_interest]\n",
    "        station_data[\"Station_ID\"] = station_id\n",
    "        station_data[\"Station_Name\"] = station_name\n",
    "        \n",
    "        # Add the data to the combined list\n",
    "        combined_data.append(station_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "# Combine and save the final DataFrame\n",
    "pd.concat(combined_data, ignore_index=True).to_csv(output_file, index=False)\n",
    "print(f\"All data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_PFDA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
